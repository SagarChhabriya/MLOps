{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ba98e3",
   "metadata": {},
   "source": [
    "### Compare Runs, Choose Model, and Deploy it to a REST API\n",
    "\n",
    "- Run a hyperparameter sweep on a training script\n",
    "- Compare the results of the runs in the MLFlow UI\n",
    "- Choose the best run and register it as a model\n",
    "- Deploy the model to a REST API\n",
    "- Build a Container image suitable for deployment to a cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c913d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "import pandas as pd \n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c33b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65ae60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1ed7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "X_train = train.drop(columns=['quality'], axis=1).values\n",
    "y_train = train['quality'].values.ravel()\n",
    "\n",
    "X_test = test.drop(columns=['quality'], axis=1).values\n",
    "y_test = test['quality'].values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8dfe4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.25, random_state=42)\n",
    "\n",
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e637c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "def train_model(params, epochs, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "\n",
    "    # Model arachitecture\n",
    "    mean = np.mean(X_train, axis=0) # mean of all columns in train set for normalization\n",
    "    var = np.var(X_train, axis=0) # var of all columns in train set for normalization\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.Input([X_train.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation='relu'), \n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Model Compilation\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=params['lr'], momentum=params['momentum']),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    # Train the ANN model with lr and momentum params with MLFlow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=64)\n",
    "\n",
    "        eval_result = model.evaluate(X_val, y_val, batch_size=64)\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        # Log the params\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "\n",
    "\n",
    "        # Log the model \n",
    "        mlflow.tensorflow.log_model(model, \"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9322e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Start a nested run for each hyperopt evaluation\n",
    "    with mlflow.start_run(nested=True):\n",
    "    # MLFlow will track the parameters and results for each run\n",
    "\n",
    "        return train_model(params, epochs=3, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "201e3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\"lr\":hp.loguniform(\"lr\",np.log(1e-5), np.log(1e-1)), \"momentum\":hp.uniform('momentum', 0.0, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a14aed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 2s/step - loss: 30.8563 - root_mean_squared_error: 5.5548\n",
      "\u001b[1m11/44\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9033 - root_mean_squared_error: 5.2802 \n",
      "\u001b[1m24/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24.7594 - root_mean_squared_error: 4.9649\n",
      "\u001b[1m39/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.7600 - root_mean_squared_error: 4.6381\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 14.2260 - root_mean_squared_error: 3.7717 - val_loss: 4.9036 - val_root_mean_squared_error: 2.2144\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 5.1150 - root_mean_squared_error: 2.2616\n",
      "\u001b[1m14/44\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5168 - root_mean_squared_error: 2.1225 \n",
      "\u001b[1m23/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2890 - root_mean_squared_error: 2.0681\n",
      "\u001b[1m32/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1833 - root_mean_squared_error: 2.0428\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4707 - root_mean_squared_error: 1.8630 - val_loss: 2.5339 - val_root_mean_squared_error: 1.5918\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - loss: 2.0805 - root_mean_squared_error: 1.4424\n",
      "\u001b[1m10/44\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4185 - root_mean_squared_error: 1.5497  \n",
      "\u001b[1m13/44\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.5006 - root_mean_squared_error: 1.5764\n",
      "\u001b[1m16/44\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5355 - root_mean_squared_error: 1.5882\n",
      "\u001b[1m20/44\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5480 - root_mean_squared_error: 1.5929\n",
      "\u001b[1m25/44\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5542 - root_mean_squared_error: 1.5955\n",
      "\u001b[1m30/44\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5475 - root_mean_squared_error: 1.5938\n",
      "\u001b[1m35/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.5367 - root_mean_squared_error: 1.5907\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.5046 - root_mean_squared_error: 1.5809\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.3441 - root_mean_squared_error: 1.5310 - val_loss: 2.0413 - val_root_mean_squared_error: 1.4287\n",
      "\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 1.7725 - root_mean_squared_error: 1.3314\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0850 - root_mean_squared_error: 1.4430 \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0413 - root_mean_squared_error: 1.4287\n",
      "\n",
      "  0%|          | 0/4 [00:06<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:42:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run melodic-snake-808 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/7bef35ec27044ae79800797862ee2854\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593\n",
      "\n",
      "🏃 View run sassy-stag-375 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/c8095472699d41c4ba3d084890ec7dfb\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 860ms/step - loss: 29.2147 - root_mean_squared_error: 5.4051\n",
      "\u001b[1m19/44\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.4667 - root_mean_squared_error: 5.4283   \n",
      "\u001b[1m32/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.5030 - root_mean_squared_error: 5.4316\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 29.0457 - root_mean_squared_error: 5.3894 - val_loss: 27.9038 - val_root_mean_squared_error: 5.2824\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 27.8307 - root_mean_squared_error: 5.2755\n",
      "\u001b[1m13/44\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6736 - root_mean_squared_error: 5.2606 \n",
      "\u001b[1m23/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7058 - root_mean_squared_error: 5.2636\n",
      "\u001b[1m37/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7304 - root_mean_squared_error: 5.2660\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 27.5948 - root_mean_squared_error: 5.2531 - val_loss: 26.5163 - val_root_mean_squared_error: 5.1494\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 25.6031 - root_mean_squared_error: 5.0600\n",
      "\u001b[1m13/44\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.3026 - root_mean_squared_error: 5.1284 \n",
      "\u001b[1m19/44\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.4133 - root_mean_squared_error: 5.1392\n",
      "\u001b[1m26/44\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.3900 - root_mean_squared_error: 5.1370\n",
      "\u001b[1m35/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.3342 - root_mean_squared_error: 5.1316\n",
      "\u001b[1m42/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.3172 - root_mean_squared_error: 5.1299\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.2358 - root_mean_squared_error: 5.1221 - val_loss: 25.1934 - val_root_mean_squared_error: 5.0193\n",
      "\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 26.2681 - root_mean_squared_error: 5.1252\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.1934 - root_mean_squared_error: 5.0193 \n",
      "\n",
      " 25%|██▌       | 1/4 [00:43<01:59, 39.86s/trial, best loss: 1.4287322759628296]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:42:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run awesome-gull-678 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/44af218a11794fcbbf77ba25ad8fd992\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "🏃 View run honorable-worm-409 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/e8b95f38e1364ca3bb04edbe3d5da5c5\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 580ms/step - loss: 35.5081 - root_mean_squared_error: 5.9589\n",
      "\u001b[1m19/44\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.6532 - root_mean_squared_error: 5.8010   \n",
      "\u001b[1m42/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.4430 - root_mean_squared_error: 5.7829\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 32.9042 - root_mean_squared_error: 5.7362 - val_loss: 32.1119 - val_root_mean_squared_error: 5.6667\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 32.6473 - root_mean_squared_error: 5.7138\n",
      "\u001b[1m12/44\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.4304 - root_mean_squared_error: 5.6947 \n",
      "\u001b[1m23/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1984 - root_mean_squared_error: 5.6743\n",
      "\u001b[1m36/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.1044 - root_mean_squared_error: 5.6660\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.8205 - root_mean_squared_error: 5.6410 - val_loss: 31.0479 - val_root_mean_squared_error: 5.5721\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 33.0013 - root_mean_squared_error: 5.7447\n",
      "\u001b[1m20/44\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.9485 - root_mean_squared_error: 5.5629 \n",
      "\u001b[1m40/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.8642 - root_mean_squared_error: 5.5554\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7692 - root_mean_squared_error: 5.5470 - val_loss: 30.0173 - val_root_mean_squared_error: 5.4788\n",
      "\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 29.4393 - root_mean_squared_error: 5.4258\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.0173 - root_mean_squared_error: 5.4788 \n",
      "\n",
      " 50%|█████     | 2/4 [01:08<01:03, 31.68s/trial, best loss: 1.4287322759628296]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:43:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run languid-skink-389 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/425fadfc630f4395b9d264547777bdab\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "🏃 View run legendary-carp-33 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/331070d3b2b2470f9319ddec53a8b4c2\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 589ms/step - loss: 33.4767 - root_mean_squared_error: 5.7859\n",
      "\u001b[1m19/44\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.4358 - root_mean_squared_error: 3.3773   \n",
      "\u001b[1m37/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4707 - root_mean_squared_error: 2.7391 \n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.1548 - root_mean_squared_error: 1.7762 - val_loss: 1.7867 - val_root_mean_squared_error: 1.3367\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 2.0689 - root_mean_squared_error: 1.4384\n",
      "\u001b[1m 7/44\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4307 - root_mean_squared_error: 1.1884 \n",
      "\u001b[1m10/44\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3282 - root_mean_squared_error: 1.1450\n",
      "\u001b[1m22/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1283 - root_mean_squared_error: 1.0553 \n",
      "\u001b[1m41/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0059 - root_mean_squared_error: 0.9970\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8236 - root_mean_squared_error: 0.9075 - val_loss: 0.7172 - val_root_mean_squared_error: 0.8469\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.5750 - root_mean_squared_error: 0.7583\n",
      "\u001b[1m20/44\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6148 - root_mean_squared_error: 0.7838 \n",
      "\u001b[1m39/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6211 - root_mean_squared_error: 0.7879\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6141 - root_mean_squared_error: 0.7837 - val_loss: 0.6243 - val_root_mean_squared_error: 0.7902\n",
      "\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5842 - root_mean_squared_error: 0.7643\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6243 - root_mean_squared_error: 0.7902 \n",
      "\n",
      " 75%|███████▌  | 3/4 [01:26<00:25, 25.61s/trial, best loss: 1.4287322759628296]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:43:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run useful-mink-275 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/0fd22c41494040b48a413a0ac7036518\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "🏃 View run persistent-wolf-333 at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/1d190648c4ba4ef3bb069899d44e30da\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593  \n",
      "\n",
      "100%|██████████| 4/4 [01:43<00:00, 25.86s/trial, best loss: 0.7901548743247986]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:43:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr': np.float64(0.020583072056206627), 'momentum': np.float64(0.4056010505429388)}\n",
      "Best rmse loss: 0.7901548743247986\n",
      "🏃 View run hyperopt_search at: http://127.0.0.1:5000/#/experiments/902051187291755593/runs/16ad25a745dd4394bcb3d0029bfe0256\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/902051187291755593\n"
     ]
    }
   ],
   "source": [
    "import mlflow.tensorflow\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment('/wine-quality')\n",
    "\n",
    "# Ensure no active runs exist\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Start a parent run for the hyperparameter optimization\n",
    "with mlflow.start_run(run_name=\"hyperopt_search\") as parent_run:\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Conduct the hyperparameter search using hyperopt\n",
    "    best = fmin(\n",
    "        fn=objective,  # train function\n",
    "        space=space,   # all the parameters\n",
    "        algo=tpe.suggest, \n",
    "        max_evals=4, \n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x['loss'])[0]\n",
    "\n",
    "    # Log the best params, loss, and model to the parent run\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run['loss'])\n",
    "    mlflow.tensorflow.log_model(best_run['model'], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best rmse loss: {best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed472b",
   "metadata": {},
   "source": [
    "TODO: Load the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0350df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model in the model registery\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
